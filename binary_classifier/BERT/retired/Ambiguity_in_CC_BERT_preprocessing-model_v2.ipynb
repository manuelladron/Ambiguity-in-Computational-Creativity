{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install python-Levenshtein\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget\n",
    "%cd ctcdecode\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.6.0-cp37-cp37m-macosx_10_10_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import * # for pad_sequence and whatnot\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\"\"\"\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.models import BPE \n",
    "from tokenizers.normalizers import Lowercase, NFKC, Sequence\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "\"\"\"\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have more information about what's happening under the hood\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget\n",
    "%cd ctcdecode\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /Users/manuelladron/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /Users/manuelladron/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/manuelladron/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = 'abcdefghijklmnopqrstuvwxyz'\n",
    "NUMBERS = '0123456789'\n",
    "class PreprocessedData_wordlevel(object):\n",
    "    def __init__(self, train_file_path, test_file_path):\n",
    "        \"\"\"\n",
    "        train_file_path = list with files\n",
    "        test_file_path = list with files\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_path = train_file_path\n",
    "        self.test_path = test_file_path\n",
    "        \n",
    "        self.VOCAB = None\n",
    "        self.VOCAB_SIZE = None\n",
    "                \n",
    "        # Automatically run it when making an instance\n",
    "        self.RUN_for_dataset()\n",
    "\n",
    "    ############ utils #########################\n",
    "    \n",
    "    def get_file(self, path):\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            data = json.loads(json.load(f))\n",
    "        return data\n",
    "    \n",
    "    def text_from_json(self, json_file):\n",
    "        all_text = []\n",
    "        for file in json_file:\n",
    "            for sample in file:\n",
    "                text_l = sample['text']\n",
    "                for sentence in text_l:\n",
    "                    sent = sentence.lower()\n",
    "                    all_text.append(sent)\n",
    "        return all_text\n",
    "    \n",
    "\n",
    "    ############## PROCESSING DATA ##############\n",
    "    \n",
    "    def remove_all_letters_in_text_tags_from_alphabet(self, alphabet, positive_tags, all_text):\n",
    "        \"\"\"\n",
    "        Takes in an alphabet, a list of tags and a list of sentences. Returns an alphabet that correspond to the \n",
    "        negative samples by substracting the positive tags\n",
    "        \"\"\"\n",
    "        # 1) Get alphabet cropped to the length of sentences\n",
    "        idx_len = len(all_text)\n",
    "        cropped_alphabet = alphabet[:idx_len]\n",
    "\n",
    "\n",
    "        # 2) If not positive tags, return cropped_alpha\n",
    "        if positive_tags == []:\n",
    "            return cropped_alphabet\n",
    "\n",
    "        # 3) Iterate over positive tags and remove them from cropped_alphabet. \n",
    "        for tag in positive_tags:\n",
    "            new_alphabet = cropped_alphabet.replace(tag, \"\")\n",
    "            cropped_alphabet = new_alphabet\n",
    "\n",
    "        # 4) The result is the negative tags! :)\n",
    "        return new_alphabet\n",
    "\n",
    "        \n",
    "    def get_all_text(self, files):\n",
    "        \"\"\"\n",
    "        Parse json file and outputs train_data (text) and numpy array labels for binary classification\n",
    "        \"\"\"\n",
    "        self.sentences = []\n",
    "        self.sentences_labels = []\n",
    "        \n",
    "        for file in files:\n",
    "            # iterate over the examples in file and grab positive and negative samples\n",
    "            for i in range(len(file)):\n",
    "                # elements from dictionary\n",
    "                positive_tags = file[i]['text-tags']\n",
    "                text_list = file[i]['text']\n",
    "\n",
    "                # valid text\n",
    "                valid_text = [ text_list[ALPHABET.index(letter)].lower() for letter in positive_tags ]\n",
    "\n",
    "                # nonvalid text\n",
    "                negative_tags = self.remove_all_letters_in_text_tags_from_alphabet(ALPHABET, positive_tags, text_list)\n",
    "                nonvalid_text = [ text_list[ALPHABET.index(letter)].lower() for letter in negative_tags ] \n",
    "                \n",
    "                # labels\n",
    "#                 pos_label = np.array([0,1])\n",
    "#                 neg_label = np.array([1,0])\n",
    "\n",
    "                pos_label = np.array([1])\n",
    "                neg_label = np.array([0])\n",
    "\n",
    "                # append sentences and labels that are not empty lists\n",
    "                if len(nonvalid_text) != 0:\n",
    "                    \n",
    "                    for nv_text in nonvalid_text:\n",
    "                        self.sentences.append(nv_text)\n",
    "                        self.sentences_labels.append(neg_label)\n",
    "\n",
    "                if len(valid_text) != 0:\n",
    "                    \n",
    "                    for v_text in valid_text:\n",
    "                        self.sentences.append(v_text)\n",
    "                        self.sentences_labels.append(pos_label)\n",
    "\n",
    "        # from list to array\n",
    "        self.sentences_labels = np.array(self.sentences_labels, dtype='int64')\n",
    "\n",
    "    def tokenize_sentences(self):\n",
    "        \n",
    "        # Tokenize all sentences and map the tokens to their word ID \n",
    "        self.inputs_ids = []\n",
    "        self.attention_masks = []\n",
    "        \n",
    "        for sent in self.sentences:                \n",
    "            # `encode_plus` will:\n",
    "            #   (1) Tokenize the sentence.\n",
    "            #   (2) Prepend the `[CLS]` token to the start.\n",
    "            #   (3) Append the `[SEP]` token to the end.\n",
    "            #   (4) Map tokens to their IDs.\n",
    "            #   (5) Pad or truncate the sentence to `max_length`\n",
    "            #   (6) Create attention masks for [PAD] tokens.\n",
    "            encoded_dict = tokenizer.encode_plus(sent,\n",
    "                                                add_special_tokens = True, # add [CLS] and [SEP]\n",
    "                                                max_length = 64,\n",
    "                                                pad_to_max_length = True,  # pad and truncate\n",
    "                                                return_attention_mask = True,\n",
    "                                                return_tensors = 'pt'\n",
    "                                                )\n",
    "            self.inputs_ids.append(encoded_dict['input_ids'])\n",
    "            self.attention_masks.append(encoded_dict['attention_mask'])\n",
    "            \n",
    "#             print('original: ', sent)\n",
    "#             print('token IDs: ', encoded_dict['input_ids'])\n",
    "\n",
    "        # Convert list to tensors\n",
    "        self.inputs_ids = torch.cat(self.inputs_ids, dim=0)\n",
    "        self.attention_masks = torch.cat(self.attention_masks, dim=0)\n",
    "        self.labels = torch.tensor(self.sentences_labels)\n",
    "        print(self.labels.shape)\n",
    "        print(self.labels.type())\n",
    "    def partition_data(self, train_percentage):\n",
    "        \n",
    "        assert len(self.inputs_ids) == len(self.sentences_labels)\n",
    "        dataset = TensorDataset(self.inputs_ids, self.attention_masks, self.labels)\n",
    "        \n",
    "        train_size = int(train_percentage * len(dataset))\n",
    "        dev_size = len(dataset) - train_size\n",
    "\n",
    "        \n",
    "        self.train_dataset, self.dev_dataset = random_split(dataset, [train_size, dev_size])\n",
    "        \n",
    "        print('{:>5,} training samples'.format(train_size))\n",
    "        print('{:>5,} validation samples'.format(dev_size))\n",
    "\n",
    "    \n",
    "    def RUN_for_dataset(self):\n",
    "        \n",
    "        # 1) get jsons\n",
    "        train_raw = []\n",
    "        for i in range(len(self.train_path)): # list with all training data from different sections\n",
    "            train_raw.append(self.get_file(self.train_path[i]))\n",
    "        \n",
    "        # 2) get text\n",
    "        self.get_all_text(train_raw)\n",
    "        print(len(self.sentences), len(self.sentences_labels))\n",
    "        # 3) tokenize at word-level\n",
    "        self.tokenize_sentences()\n",
    "        \n",
    "        # 4) partition data\n",
    "        self.partition_data(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9628 9628\n",
      "torch.Size([9628, 1])\n",
      "torch.LongTensor\n",
      "7,702 training samples\n",
      "1,926 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = PreprocessedData_wordlevel([\"./data/architecture_dz-cleaned-tagged.json\",\n",
    "                            \"./data/design_dz-cleaned-tagged.json\",\n",
    "                           \"./data/technology_dz-cleaned-tagged.json\", ], \n",
    "                           [\"./data/architecture_dz-cleaned.json\", \n",
    "                            \"./data/design_dz-cleaned.json\",\n",
    "                           \"./data/technology_dz-cleaned.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.train_dataset\n",
    "dev_dataset = dataset.dev_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(device)\n",
    "num_workers = 8 if cuda else 0 \n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            dev_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(dev_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /Users/manuelladron/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /Users/manuelladron/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training:\n",
    "\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass.\n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "Evalution:\n",
    "\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(epochs, train, test, train_name, val_name, name_long, name_short):\n",
    "    BCK = (3/255, 5/255, 25/255)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_facecolor(BCK)\n",
    "    ax.plot(epochs, train, 'g', label=train_name, c=\"mediumvioletred\")\n",
    "    ax.plot(epochs, test, 'b', label=val_name, c=\"darkturquoise\")\n",
    "    ax.set_title(name_long)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel(name_short)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, scheduler):\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(loader):\n",
    "        \n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)  # batch x seq_length\n",
    "        b_input_mask = batch[1].to(device) # batch x seq_length\n",
    "        b_labels = batch[2].to(device)     # batch x 2 (num_classes, binary)\n",
    "\n",
    "#         print(\"inputs_ids shape: \", b_input_ids.shape)\n",
    "#         print(\"input_mask shape: \", b_input_mask.shape)\n",
    "#         print(\"labels shape: \", b_labels.shape)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        loss = loss.clone().detach().requires_grad_(True)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        \n",
    "        accuracy = flat_accuracy(logits, b_labels)\n",
    "        running_acc += accuracy\n",
    "        \n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    running_loss /= len(loader)\n",
    "    running_acc /= len(loader)\n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(running_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    return running_loss, running_acc, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in loader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, # bc of single sentences?\n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        running_acc += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    running_acc /= len(validation_dataloader)\n",
    "    \n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    running_loss /= len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(running_loss))\n",
    "    print(\"  Validation Accuracy: {0:.2f}\".format(running_acc))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    return running_loss, running_acc, validation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epochs(model, train_dataloader, validation_dataloader, optimizer, scheduler, epochs):\n",
    "    # This training code is based on the `run_glue.py` script here:\n",
    "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "    # Set the seed value all over the place to make this reproducible.\n",
    "    seed_val = 42\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    # We'll store a number of quantities such as training and validation loss, \n",
    "    # validation accuracy, and timings.\n",
    "    training_stats = []\n",
    "\n",
    "    # Measure the total training time for the whole run.\n",
    "    total_t0 = time.time()\n",
    "\n",
    "    train_losses, train_accs = [], []\n",
    "    test_losses, test_accs = [] , []\n",
    "    epochs_l = []\n",
    "    # For each epoch...\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "\n",
    "        # Perform one full pass over the training set.\n",
    "\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        train_loss, train_acc, train_time = train(model, train_dataloader, optimizer, scheduler)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "        # After the completion of each training epoch, measure our performance on\n",
    "        # our validation set.\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        \n",
    "        test_loss, test_acc, test_time = test(model, validation_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "\n",
    "\n",
    "        # Record all statistics from this epoch.\n",
    "        training_stats.append(\n",
    "            {\n",
    "                'epoch': epoch_i + 1,\n",
    "                'Training Loss': train_loss,\n",
    "                'Training Accur.': train_acc,\n",
    "                'Valid. Loss': test_loss,\n",
    "                'Valid. Accur.': test_acc,\n",
    "                'Training Time': train_time,\n",
    "                'Validation Time': test_time\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Epochs\n",
    "        epochs_l.append(epoch_i)\n",
    "        \n",
    "        # Draw Graphs\n",
    "        print(\"list of epochs: \")\n",
    "        print(\"train_accs, test_accs: \", train_accs, test_accs)\n",
    "        print(\"train_losses, test_losses: \", train_losses, test_losses)\n",
    "        make_graph(epochs_l, train_losses, test_losses, 'Training loss', 'Testing loss',\n",
    "                       'Training and Testing loss', 'Loss')\n",
    "        make_graph(epochs_l, train_accs, test_accs, 'Training Acc', 'Testing Acc',\n",
    "                       'Training and Testing Accuracy', 'Accuracy')\n",
    "\n",
    "       \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "    return train_losses, train_accs, test_losses, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:01:14.\n",
      "  Batch    80  of    241.    Elapsed: 0:02:33.\n",
      "  Batch   120  of    241.    Elapsed: 0:03:50.\n",
      "  Batch   160  of    241.    Elapsed: 0:05:07.\n",
      "  Batch   200  of    241.    Elapsed: 0:06:30.\n",
      "  Batch   240  of    241.    Elapsed: 0:07:47.\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:07:48\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.92\n",
      "  Validation Accuracy: 0.38\n",
      "  Validation took: 0:01:44\n",
      "list of epochs: \n",
      "train_accs, test_accs:  [0.0] [0.381318306010929]\n",
      "train_losses, test_losses:  [0.9084275688867846] [0.9237584461931323]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:01:15.\n",
      "  Batch    80  of    241.    Elapsed: 0:02:29.\n",
      "  Batch   120  of    241.    Elapsed: 0:03:44.\n",
      "  Batch   160  of    241.    Elapsed: 0:04:58.\n",
      "  Batch   200  of    241.    Elapsed: 0:06:12.\n",
      "  Batch   240  of    241.    Elapsed: 0:07:27.\n",
      "\n",
      "  Average training loss: 0.91\n",
      "  Training epcoh took: 0:07:28\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 0.92\n",
      "  Validation Accuracy: 0.38\n",
      "  Validation took: 0:01:42\n",
      "list of epochs: \n",
      "train_accs, test_accs:  [0.0, 0.0] [0.381318306010929, 0.381318306010929]\n",
      "train_losses, test_losses:  [0.9084275688867846, 0.9082840737960151] [0.9237584461931323, 0.9237584461931323]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, test_losses, test_accs = run_epochs(model, train_dataloader, validation_dataloader, optimizer, scheduler, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
